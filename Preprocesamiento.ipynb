{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de Audio\n",
    "\n",
    "Este notebook lleva a cabo varios pasos de procesamiento en señales de audio, incluyendo la reducción de ruido, eliminación de silencios, normalización, y segmentación.\n",
    "\n",
    "A lo largo del proceso, se generan varios archivos de audio que ilustran cada paso. Al final, se presentan visualizaciones para comparar las señales antes y después del procesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice\n",
    "1. [Importación de Bibliotecas](#importación)\n",
    "2. [Definición de Funciones para el Procesamiento de Audio](#definición)\n",
    "3. [Proceso de Reducción de Ruido](#proceso_ruido)\n",
    "4. [Proceso de Eliminación de Silencios](#proceso_silencios)\n",
    "5. [Proceso de Normalización del Audio](#proceso_normalización)\n",
    "6. [Proceso de Preenfasis, Segmentación y Ventaneo](#proceso_segmentación)\n",
    "7. [Archivos generados](#archivos)\n",
    "8. [Gráficas](#gráficas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"importación\"></a>\n",
    "## 1. Importación de Bibliotecas\n",
    "En esta sección, se importan todas las librerías necesarias para el análisis y procesamiento de audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # Biblioteca para operaciones matemáticas avanzadas y manejo de arreglos multidimensionales.\n",
    "\n",
    "# noisereduce es una biblioteca para reducir el ruido en señales de audio.\n",
    "import noisereduce as nr\n",
    "\n",
    "# pydub es una biblioteca que proporciona herramientas simples para manipular audio.\n",
    "from pydub import AudioSegment  # Utilizado para trabajar con segmentos de audio (carga, exporta, operaciones básicas).\n",
    "from pydub.silence import split_on_silence  # Función para dividir un audio basado en silencios detectados.\n",
    "\n",
    "# Herramientas para el análisis de señales.\n",
    "from scipy.fft import fft, fftfreq  # Funciones para realizar transformada rápida de Fourier (FFT) y calcular las frecuencias asociadas.\n",
    "\n",
    "# librosa es una biblioteca para el análisis y procesamiento de audio.\n",
    "import librosa  # Biblioteca principal.\n",
    "import librosa.display  # Herramientas para visualizar datos de audio, como espectrogramas.\n",
    "\n",
    "# soundfile es utilizado para leer y escribir archivos de audio en diversos formatos.\n",
    "import soundfile as sf  \n",
    "\n",
    "# Bibliotecas estándar de Python para trabajar con archivos temporales y operaciones del sistema.\n",
    "import tempfile  # Herramientas para crear archivos y directorios temporales.\n",
    "import os  # Herramientas relacionadas con el sistema operativo, como la manipulación de rutas.\n",
    "\n",
    "# subprocess permite interactuar con comandos y programas externos desde Python.\n",
    "import subprocess\n",
    "\n",
    "# io proporciona las herramientas básicas de Python para trabajar con flujos de datos (streams).\n",
    "import io  \n",
    "from io import BytesIO  # Clase para trabajar con flujos de datos en memoria como si fueran archivos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"definición\"></a>\n",
    "## 2. Definición de Funciones para el Procesamiento de Audio\n",
    "Se presentan a continuación las funciones que se han definido para llevar a cabo diversas tareas relacionadas con el análisis y procesamiento del audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Función para reducir el ruido de un audio dado\n",
    "La función utiliza la biblioteca [**noisereduce**](https://pypi.org/project/noisereduce/) para reducir el ruido en una señal de audio.\n",
    "Luego, la señal de audio filtrada se convierte al formato int16 antes de devolverse.\n",
    "\n",
    ">**Parámetros:**\n",
    "* **canal_de_audio (np.array):** Un arreglo numpy que representa la señal de audio a filtrar.\n",
    "* **fs (int):** La tasa de muestreo de la señal de audio.\n",
    "\n",
    ">**Retorna:**\n",
    "* **np.array:** La señal de audio filtrada en formato int16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduccion_de_ruido(canal_de_audio, fs):\n",
    "    # Aplicar la reducción de ruido utilizando noisereduce\n",
    "    audio_filtrado_float = nr.reduce_noise(y=canal_de_audio, sr=fs)\n",
    "    # Convertir el audio filtrado a formato int16\n",
    "    return np.int16(audio_filtrado_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Elimina los segmentos de silencio de una señal de audio dada\n",
    "\n",
    "Esta función primero guarda el audio en un archivo temporal en formato WAV.\n",
    "Luego, utiliza la función split_on_silence de la biblioteca [**pydub**](https://pypi.org/project/pydub/) para detectar y eliminar silencios.\n",
    "Finalmente, se elimina el archivo temporal y se devuelve la señal de audio sin silencios.\n",
    "\n",
    ">**Parámetros:**\n",
    "* **audio (np.array):** Un arreglo numpy que representa la señal de audio.\n",
    "* **sr (int):** La tasa de muestreo de la señal de audio.\n",
    "* **longitud_minima_de_silencio (int, opcional):** Duración mínima (en ms) para considerar un segmento como silencio. Por defecto es 100 ms.\n",
    "* **umbral_de_silencio (int, opcional):** Umbral en dBFS por debajo del cual se considera silencio. Por defecto es -60 dBFS.\n",
    "\n",
    ">**Retorna:**\n",
    "* **np.array:** La señal de audio sin los segmentos de silencio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eliminar_silencios(audio, sr, longitud_minima_de_silencio=100, umbral_de_silencio=-60):\n",
    "    # Crear un archivo temporal para guardar el audio como WAV\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as archivo_temporal_silencios:\n",
    "        sf.write(archivo_temporal_silencios.name, audio, sr, format='wav')\n",
    "        # Cargar el archivo temporal como un objeto AudioSegment\n",
    "        representacion_del_audio_silencios = AudioSegment.from_wav(archivo_temporal_silencios.name)\n",
    "    \n",
    "    # Eliminar silencios del audio usando la función split_on_silence\n",
    "    representaciones_de_audio_sin_silencios = split_on_silence(representacion_del_audio_silencios, min_silence_len=longitud_minima_de_silencio, silence_thresh=umbral_de_silencio)\n",
    "    audio_sin_silencios = np.concatenate([np.array(representacion_de_audio_sin_silencios.get_array_of_samples()) / 32767 for representacion_de_audio_sin_silencios in representaciones_de_audio_sin_silencios])\n",
    "    #32767 -> Este valor es debido a la conversion de audio digital en int16 a punto flotante en el rango de -1 a 1 \n",
    "    \n",
    "    # Cerrar y eliminar el archivo temporal\n",
    "    archivo_temporal_silencios.close()\n",
    "    os.unlink(archivo_temporal_silencios.name)\n",
    "    \n",
    "    return audio_sin_silencios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.  Normaliza una señal de audio\n",
    "La función normaliza la señal de audio dividiendo cada muestra por el valor máximo absoluto de la señal.\n",
    "Esto asegura que la señal resultante esté en el rango de [-1, 1].\n",
    "\n",
    ">**Parámetros:**\n",
    "* **audio (np.array):** Un arreglo numpy que representa la señal de audio a normalizar.\n",
    "\n",
    ">**Retorna:**\n",
    "* **np.array:** La señal de audio normalizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para normalizar el audio\n",
    "def normalizar_audio(audio):\n",
    "    return audio / np.max(np.abs(audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Guarda una señal de audio en un objeto BytesIO en formato WAV\n",
    "Esta función toma una señal de audio y su tasa de muestreo, y la guarda \n",
    "en un objeto BytesIO en formato WAV. Esto permite trabajar con el audio como \n",
    "si estuviera en un archivo real, pero manteniendo todo en memoria.\n",
    "\n",
    ">**Parámetros:**\n",
    "* **audio (np.array):** Un arreglo numpy que representa la señal de audio a guardar.\n",
    "* **sr (int):** La tasa de muestreo de la señal de audio.\n",
    "\n",
    ">**Retorna:**\n",
    "* **BytesIO:** Un objeto BytesIO que contiene la señal de audio en formato WAV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para guardar el audio en un objeto BytesIO en formato WAV\n",
    "def guardar_wav_en_la_memoria(audio, sr):\n",
    "    buffer = BytesIO()\n",
    "    sf.write(buffer, audio, sr, format='WAV')\n",
    "    buffer.seek(0)\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Convierte un objeto BytesIO con un archivo WAV a formato MP3 utilizando FFmpeg\n",
    "Esta función toma un objeto BytesIO que contiene una señal de audio en formato WAV \n",
    "y lo convierte a un archivo MP3. El archivo resultante se guarda en el sistema de archivos \n",
    "en la ruta especificada.\n",
    "\n",
    "> **Nota:** Es necesario tener instalado FFmpeg y que este esté disponible en el PATH del sistema.\n",
    "\n",
    ">**Parámetros:**\n",
    "* **buffer_de_entrada (BytesIO):** Objeto BytesIO que contiene la señal de audio en formato WAV.\n",
    "* **ruta_de_salida_normalizada (str):** Ruta donde se guardará el archivo MP3 resultante.\n",
    "\n",
    ">**Retorna:**\n",
    "* Esta función no devuelve ningún valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para convertir un objeto BytesIO con un archivo WAV a MP3 utilizando FFmpeg\n",
    "def convertir_wav_a_mp3(buffer_de_entrada, ruta_de_salida_normalizada):\n",
    "    comando = ['ffmpeg', '-i', '-', '-codec:a', 'libmp3lame', '-qscale:a', '2', ruta_de_salida_normalizada]\n",
    "    proceso = subprocess.Popen(comando, stdin=subprocess.PIPE, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    proceso.communicate(input=buffer_de_entrada.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Aplica un filtro de preénfasis a una señal dada\n",
    "El preénfasis es una técnica que acentúa o amplifica las altas frecuencias de una señal \n",
    "para equilibrar su espectro. Es comúnmente utilizado en el procesamiento de voz para \n",
    "mejorar la calidad de operaciones posteriores.\n",
    "\n",
    "La formula del filtro de preénfasis es:\n",
    "$y[n] = x[n] - \\alpha \\times x [n-1]$\n",
    "\n",
    "Donde:\n",
    "- $y[n])$ es la señal de salida.\n",
    "- $x[n]$ es la señal de entrada.\n",
    "- $\\alpha$ es el coeficiente de preénfasis.\n",
    "\n",
    ">**Parámetros:**\n",
    "* **senial (np.array):** Un arreglo numpy que representa la señal a la que se le aplicará el preénfasis.\n",
    "* **alpha (float, opcional):** El coeficiente de preénfasis. Por defecto es 0.97.\n",
    "\n",
    ">**Retorna:**\n",
    "* **np.array:** La señal con preénfasis aplicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filtro_preenfasis(senial, alpha=0.97):\n",
    "    return np.append(senial[0], senial[1:] - alpha * senial[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.  Segmenta y procesa un archivo de audio \n",
    "La función carga un archivo de audio y lo segmenta en frames utilizando una ventana deslizante. \n",
    "Además, aplica un filtro de preénfasis y una ventana de Hamming a cada frame.\n",
    "\n",
    ">**Parámetros:**\n",
    "* **nombre_del_archivo_de_audio_a_filtrar_Segmentar_ventanear (str):** Ruta del archivo de audio a procesar.\n",
    "* **duracion_del_frame (int, opcional):** Duración de cada frame en milisegundos. Por defecto es 20 ms.\n",
    "* **minima_duracion_del_audio_en_seg (int, opcional):** Duración mínima del audio en segundos para procesar. Por defecto es 2 segundos.\n",
    "* **frames_totales (int, opcional):** Número máximo de frames a considerar. Por defecto es 100.\n",
    "\n",
    ">**Retorna:**\n",
    "* **tuple:** Una tupla con dos np.arrays. El primero contiene frames con el filtro de preénfasis y ventana de Hamming aplicados. El segundo contiene frames originales sin ningún procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segmentacion_del_audio(nombre_del_archivo_de_audio_a_filtrar_Segmentar_ventanear, \n",
    "                           duracion_del_frame=20, \n",
    "                           minima_duracion_del_audio_en_seg=2, \n",
    "                           frames_totales=100):\n",
    "    \n",
    "    # Cargar el archivo de audio\n",
    "    senial_original_a_filtrar_segmentar_ventanear, sr_a_filtrar_segmentar_ventanear = librosa.load(nombre_del_archivo_de_audio_a_filtrar_Segmentar_ventanear, sr=None)\n",
    "   \n",
    "    # Verificar si el audio tiene una duración mínima de 2 segundos\n",
    "    if len(senial_original_a_filtrar_segmentar_ventanear) < minima_duracion_del_audio_en_seg * sr_a_filtrar_segmentar_ventanear:\n",
    "        return None\n",
    "    \n",
    "    # Aplicar el filtro de preénfasis\n",
    "    senial_filtrada_con_preenfasis = filtro_preenfasis(senial_original_a_filtrar_segmentar_ventanear)\n",
    "    \n",
    "    # Calcular la longitud de la ventana y el paso (hop) en muestras\n",
    "    longitud_de_frame = int(sr_a_filtrar_segmentar_ventanear * duracion_del_frame / 1000)\n",
    "    solapamiento = longitud_de_frame // 2\n",
    "\n",
    "    # Aplicar la ventana deslizante para extraer los frames\n",
    "    frames_con_preenfasis = librosa.util.frame(senial_filtrada_con_preenfasis, frame_length=longitud_de_frame, hop_length=solapamiento)\n",
    "    frames_sin_preenfasis = librosa.util.frame(senial_original_a_filtrar_segmentar_ventanear, frame_length=longitud_de_frame, hop_length=solapamiento)\n",
    "    \n",
    "    # Limitar la cantidad de frames a frames_totales\n",
    "    frames_con_preenfasis = frames_con_preenfasis[:, :frames_totales]\n",
    "    frames_sin_preenfasis = frames_sin_preenfasis[:, :frames_totales]\n",
    "\n",
    "    # Aplicar la ventana de Hamming a cada frame\n",
    "    ventana_de_hamming = np.hamming(longitud_de_frame)\n",
    "    frames_con_preenfasis = frames_con_preenfasis * ventana_de_hamming[:, np.newaxis]\n",
    "\n",
    "    return frames_con_preenfasis, frames_sin_preenfasis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8. Guarda los frames en un archivo utilizando el formato numpy\n",
    "Esta función toma un conjunto de frames (representados como un arreglo numpy) y los guarda \n",
    "en un archivo en el formato específico de numpy (.npy).\n",
    "\n",
    ">**Parámetros:**\n",
    "* **frames (np.array):** Arreglo numpy que contiene los frames a guardar.\n",
    "* **ruta_de_archivo_de_salida_segmentado (str):** Ruta donde se guardará el archivo con los frames.\n",
    "\n",
    ">**Retorna:**\n",
    "* Esta función no devuelve ningún valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def guardar_frames_en_un_archivo(frames, ruta_de_archivo_de_salida_segmentado):\n",
    "    np.save(ruta_de_archivo_de_salida_segmentado, frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9. Carga los frames de un archivo guardado en el formato numpy\n",
    "Esta función carga un conjunto de frames (representados como un arreglo numpy) desde un archivo \n",
    "que ha sido guardado en el formato específico de numpy (.npy).\n",
    "\n",
    ">**Parámetros:**\n",
    "* **archivo_de_entrada (str):** Ruta del archivo que contiene los frames guardados en formato numpy.\n",
    "\n",
    ">**Retorna:**\n",
    "* **np.array:** Arreglo numpy que contiene los frames cargados del archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_frames_from_file(archivo_de_entrada):\n",
    "    return np.load(archivo_de_entrada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"proceso_ruido\"></a>\n",
    "## 3. Proceso de Reducción de Ruido\n",
    "En esta sección, se lleva a cabo el proceso de reducción de ruido en un archivo de audio específico. Se emplea una técnica que busca minimizar el ruido presente para mejorar la claridad del audio. Este proceso se encarga de cargar un archivo de audio en formato MP3, separar sus canales (si es estéreo), cambiar la tasa de muestreo, aplicar un proceso de reducción de ruido y, finalmente, guardar la versión filtrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nombre del archivo de audio original\n",
    "nombre_del_archivo_de_audio_a_quitarle_el_ruido = \"audio_prueba.mp3\"\n",
    "\n",
    "# 1. Cargar el archivo de audio\n",
    "representacion_del_audio_ruido = AudioSegment.from_mp3(nombre_del_archivo_de_audio_a_quitarle_el_ruido)\n",
    "muestras_ruido = np.array(representacion_del_audio_ruido.get_array_of_samples())\n",
    "fs_original = representacion_del_audio_ruido.frame_rate\n",
    "\n",
    "# 2. Definir la tasa de muestreo objetivo\n",
    "fs_objetivo = 32000\n",
    "\n",
    "# 3. Separar los canales si el audio es estéreo\n",
    "if representacion_del_audio_ruido.channels == 2:\n",
    "    muestras_del_canal_izquierdo = muestras_ruido[::2]\n",
    "    muestras_del_canal_derecho = muestras_ruido[1::2]\n",
    "else:\n",
    "    muestras_del_canal_izquierdo = muestras_ruido\n",
    "\n",
    "# 4. Cambiar la tasa de muestreo a la tasa objetivo para cada canal\n",
    "muestras_del_canal_izquierdo = librosa.resample(muestras_del_canal_izquierdo.astype(np.float32), orig_sr=fs_original, target_sr=fs_objetivo)\n",
    "if representacion_del_audio_ruido.channels == 2:\n",
    "    muestras_del_canal_derecho = librosa.resample(muestras_del_canal_derecho.astype(np.float32), orig_sr=fs_original, target_sr=fs_objetivo)\n",
    "\n",
    "# 5. Aplicar la reducción de ruido a cada canal de manera independiente\n",
    "muestras_filtradas_del_canal_izquierdo = reduccion_de_ruido(muestras_del_canal_izquierdo, fs_objetivo)\n",
    "if representacion_del_audio_ruido.channels == 2:\n",
    "    muestras_filtradas_del_canal_derecho = reduccion_de_ruido(muestras_del_canal_derecho, fs_objetivo)\n",
    "\n",
    "# 6. Si el audio es estéreo, combinar los canales filtrados \n",
    "if representacion_del_audio_ruido.channels == 2:\n",
    "    muestras_filtradas = np.empty(muestras_filtradas_del_canal_izquierdo.size + muestras_filtradas_del_canal_derecho.size, dtype=np.int16)\n",
    "    muestras_filtradas[::2] = muestras_filtradas_del_canal_izquierdo\n",
    "    muestras_filtradas[1::2] = muestras_filtradas_del_canal_derecho\n",
    "else:\n",
    "    muestras_filtradas = muestras_filtradas_del_canal_izquierdo\n",
    "\n",
    "# 7. Crear una representación de audio filtrado\n",
    "representacion_del_audio_filtrado = AudioSegment(\n",
    "    muestras_filtradas.tobytes(),\n",
    "    frame_rate=fs_objetivo,\n",
    "    sample_width=muestras_filtradas.dtype.itemsize,\n",
    "    channels=representacion_del_audio_ruido.channels\n",
    ")\n",
    "\n",
    "# 8. Definir la ruta de archivo de salida y guardar el audio filtrado en formato MP3\n",
    "ruta_de_archivo_de_salida_ruido = os.path.splitext(nombre_del_archivo_de_audio_a_quitarle_el_ruido)[0] + '_con_reduccion_de_ruido.mp3'\n",
    "representacion_del_audio_filtrado.export(ruta_de_archivo_de_salida_ruido, format=\"mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"proceso_silencios\"></a>\n",
    "## 4. Proceso de Eliminación de Silencios\n",
    "El audio puede tener silencios o pausas que no aportan información. En esta sección, se identifican y eliminan dichos silencios. Este proceso se encarga de cargar un archivo de audio previamente procesado (en el que se ha reducido el ruido), eliminar los silencios largos que pueda tener, y finalmente guardar el audio procesado en un nuevo archivo MP3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Definir la ruta al archivo de entrada\n",
    "nombre_del_archivo_de_audio_a_eliminar_silencios = ruta_de_archivo_de_salida_ruido\n",
    "\n",
    "# 2. Cargar el archivo de audio\n",
    "audio_silencios, sr_silencios = librosa.load(nombre_del_archivo_de_audio_a_eliminar_silencios, sr=None)\n",
    "\n",
    "# 3. Eliminar los silencios del audio\n",
    "audio_sin_silencios = eliminar_silencios(audio_silencios, sr_silencios)\n",
    "\n",
    "# 4. Definir la ruta del archivo de salida\n",
    "ruta_de_salida_de_archivo_silencios = os.path.splitext(nombre_del_archivo_de_audio_a_quitarle_el_ruido)[0] + '_sin_silencios_largos.mp3'\n",
    "\n",
    "# 5. Guardar el audio procesado en un archivo MP3\n",
    "with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as archivo_temporal_silencios:\n",
    "    # Convertir el audio a formato WAV y guardar en un archivo temporal\n",
    "    sf.write(archivo_temporal_silencios.name, audio_sin_silencios, sr_silencios, format='wav')\n",
    "    # Convertir el archivo WAV temporal a MP3 y guardar en la ruta definida\n",
    "    representacion_del_audio_silencios = AudioSegment.from_wav(archivo_temporal_silencios.name)\n",
    "    representacion_del_audio_silencios.export(ruta_de_salida_de_archivo_silencios, format='mp3')\n",
    "    # Cerrar y eliminar el archivo temporal\n",
    "    archivo_temporal_silencios.close()\n",
    "    os.unlink(archivo_temporal_silencios.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"proceso_normalización\"></a>\n",
    "## 5. Proceso de Normalización del Audio\n",
    "Para asegurar que el audio tenga un volumen uniforme, se aplica un proceso de normalización que ajusta la amplitud del audio. Este proceso toma un archivo de audio en el que previamente se han eliminado los silencios largos, lo normaliza (ajusta el volumen para que su amplitud máxima sea 1) y luego guarda el resultado en un nuevo archivo MP3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Cargar el archivo de audio previamente procesado (silencios eliminados)\n",
    "nombre_del_archivo_de_audio_a_normalizar = ruta_de_salida_de_archivo_silencios\n",
    "audio_a_normalizar, sr_a_normalizar = librosa.load(nombre_del_archivo_de_audio_a_normalizar, sr=None)\n",
    "\n",
    "# 2. Aplicar la normalización al audio\n",
    "audio_normalizado = normalizar_audio(audio_a_normalizar)\n",
    "\n",
    "# 3. Guardar el audio normalizado en un objeto temporal (BytesIO) en formato WAV\n",
    "buffer_wav_de_salida = guardar_wav_en_la_memoria(audio_normalizado, sr_a_normalizar)\n",
    "\n",
    "# 4. Definir la ruta de salida para el audio normalizado y convertirlo a formato MP3\n",
    "salida_del_audio_normalizado = os.path.splitext(nombre_del_archivo_de_audio_a_quitarle_el_ruido)[0] + '_normalizado.mp3'\n",
    "convertir_wav_a_mp3(buffer_wav_de_salida, salida_del_audio_normalizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"proceso_segmentación\"></a>\n",
    "## 6. Proceso de Preenfasis, Segmentación y Ventaneo\n",
    "Se aplican técnicas adicionales al audio, como el preénfasis, para mejorar ciertas características del sonido. Además, se segmenta el audio y se aplica un proceso de ventaneo. Este proceso toma un archivo de audio que ha sido previamente normalizado, lo segmenta en frames utilizando la función segmentacion_del_audio (que también aplica un filtro de preénfasis), y finalmente guarda estos frames en archivos .npy utilizando el formato específico de NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Definir el nombre del archivo de audio a procesar\n",
    "nombre_del_archivo_de_audio_a_filtrar_Segmentar_ventanear = salida_del_audio_normalizado\n",
    "\n",
    "# 2. Segmentar el audio en frames\n",
    "[frames_con_preenfasis, frames_sin_preenfasis] = segmentacion_del_audio(nombre_del_archivo_de_audio_a_filtrar_Segmentar_ventanear)\n",
    "\n",
    "# 3. Guardar los frames con preénfasis en un archivo numpy\n",
    "ruta_de_archivo_de_salida_segmentado_con_preenfasis = os.path.splitext(nombre_del_archivo_de_audio_a_quitarle_el_ruido)[0] + '_frames_con_preenfasis.npy'\n",
    "guardar_frames_en_un_archivo(frames_con_preenfasis, ruta_de_archivo_de_salida_segmentado_con_preenfasis)\n",
    "\n",
    "# 4. Guardar los frames sin preénfasis en un archivo numpy\n",
    "ruta_de_archivo_de_salida_segmentado_sin_preenfasis = os.path.splitext(nombre_del_archivo_de_audio_a_quitarle_el_ruido)[0] + '_frames_sin_preenfasis.npy'\n",
    "guardar_frames_en_un_archivo(frames_sin_preenfasis, ruta_de_archivo_de_salida_segmentado_sin_preenfasis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"archivos\"></a>\n",
    "## 7. Archivos Generados\n",
    "\n",
    "Durante el proceso, se han generado varios archivos de audio que representan cada paso del procesamiento. Estos archivos se pueden encontrar en la carpeta [recursos](https://github.com/JazminPS/Gender-and-Age-Recognition-System-from-Speech/tree/main/recursos) y son:\n",
    "\n",
    "1. `audio_prueba_con_reduccion_de_ruido.mp3`: Audio con ruido reducido.\n",
    "2. `audio_prueba_sin_silencios_largos.mp3`: Audio sin silencios prolongados.\n",
    "3. `audio_prueba_normalizado.mp3`: Audio normalizado.\n",
    "\n",
    "Además, se han guardado segmentos de audio en formato `.npy` que representan la señal después del preénfasis, segmentación, y ventaneo:\n",
    "\n",
    "1. `audio_prueba_frames_con_preenfasis.npy`: Frames del audio con filtro preenfasis.\n",
    "2. `audio_prueba_frames_sin_preenfasis.npy`: Frames del audio sin filtro preenfasis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"gráficas\"></a>\n",
    "## 8. Gráficas\n",
    "\n",
    "Las gráficas a continuación ilustran el proceso y resultados de la reducción de ruido, eliminación de silencios largos, normalización y segmentación del audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1. Señal de audio filtrada para la reducción del ruido\n",
    "\n",
    "Se observa que se eliminaron algunas frecuencias en el espectro de la señal debido al filtrado del ruido. De igual manera se observa una señal más definida en el dominio del tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Comparación entre la señal de audio original y la señal filtrada para la reducción del ruido](https://raw.githubusercontent.com/JazminPS/Gender-and-Age-Recognition-System-from-Speech/main/recursos/Se%C3%B1al_con_Reduccion_de_Ruido.png\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Señal de audio sin silencios largos\n",
    "\n",
    "Se observa que se redujo la duración de la señal en el dominio del tiempo debido a la eliminación de los silencios largos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Comparación entre la señal de audio original y la señal sin silencios largos](https://raw.githubusercontent.com/JazminPS/Gender-and-Age-Recognition-System-from-Speech/main/recursos/Señal_sin_silencios_largos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3. Señal de audio normalizada\n",
    "\n",
    "Se observa que la forma de las señales tanto en el dominio del tiempo como en el dominio de la frecuencia es la misma, no se modificó, la única diferencia se encuentra en las amplitudes de cada señal, ya que la normalizada varía entre [-1 y 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Comparación entre la señal de audio original y la señal normalizada](https://raw.githubusercontent.com/JazminPS/Gender-and-Age-Recognition-System-from-Speech/main/recursos/Señal_normalizada.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4. Señal filtrada con un filtro preénfasis\n",
    "\n",
    "Como se muestra en la gráfica en el espectro de la señal se equilibran las frecuencias altas y bajas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Comparación entre la señal de audio original y la señal con filtro preénfasis](https://raw.githubusercontent.com/JazminPS/Gender-and-Age-Recognition-System-from-Speech/main/recursos/Señal_con_filtro_preenfasis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5. Segmentación y ventaneo\n",
    "\n",
    "En la gráfica se muestra la ventana de Hamming utilizada junto con la comparación entre un frame perteneciente a la señal antes y después de aplicarle dicha ventana.\n",
    "Se aprecia que al aplicarle la ventana al segmento se suavizaron los bordes lo cual justamente es el objetivo del ventaneo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Segmentacion y ventaneo](https://raw.githubusercontent.com/JazminPS/Gender-and-Age-Recognition-System-from-Speech/main/recursos/Segmentacion_y_ventaneo.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
